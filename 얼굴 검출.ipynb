{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 얼굴 검출(이미지)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분류기 생성\n",
    "face_cascade = cv2.CascadeClassifier('./data/haarcascade_frontalface_default.xml')\n",
    "\n",
    "img = cv2.imread('./img/children.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_cascade.detectMultiScale(gray)\n",
    "\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "    roi = gray[y:y+h, x:x+w]\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 얼굴 검출(카메라)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분류기 생성\n",
    "face_cascade = cv2.CascadeClassifier('./data/haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(-1)\n",
    "while cap.isOpened():\n",
    "    ret, img = cap.read()\n",
    "    if ret:\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor = 1.3, minNeighbors = 5, minSize = (80, 80))\n",
    "        \n",
    "        for(x, y, w, h) in faces:\n",
    "            cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "            roi = gray[y:y+h, x:x+w]\n",
    "        \n",
    "        cv2.imshow('face detect', img)\n",
    "    else:\n",
    "        break\n",
    "    if cv2.waitKey(5) == 27:\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LBP 얼굴 인식을 위한 샘플 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Insert User Name(Only Alphabet): sk\n",
      "Insert User Id(Non-Duplicate number): 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Samples Completed\n"
     ]
    }
   ],
   "source": [
    "base_dir = './faces/'\n",
    "target_cnt = 400\n",
    "cnt = 0\n",
    "\n",
    "# 분류기 생성\n",
    "face_classifier = cv2.CascadeClassifier('./data/haarcascade_frontalface_default.xml')\n",
    "\n",
    "name = input(\"Insert User Name(Only Alphabet):\")\n",
    "id = input(\"Insert User Id(Non-Duplicate number):\")\n",
    "dir = os.path.join(base_dir, name+'_' + id)\n",
    "if not os.path.exists(dir):\n",
    "    os.mkdir(dir)\n",
    "\n",
    "cap = cv2.VideoCapture(-1)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        img = frame.copy()\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "        if len(faces) == 1:\n",
    "            (x, y, w, h) = faces[0]\n",
    "            \n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 1)\n",
    "            face = gray[y:y+h, x:x+w]\n",
    "            face = cv2.resize(face, (200, 200))\n",
    "            file_name_path = os.path.join(dir, str(cnt) + '.jpg')\n",
    "            cv2.imwrite(file_name_path, face)\n",
    "            cv2.putText(frame, str(cnt), (x, y), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 2)\n",
    "            cnt += 1\n",
    "        else:\n",
    "            # 얼굴이 없거나 1 이상인 경우\n",
    "            if len(faces) == 0:\n",
    "                msg = \"no face.\"\n",
    "            elif len(faces) > 1:\n",
    "                msg = \"too many face.\"\n",
    "            cv2.putText(frame, msg, (10, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 255))\n",
    "        cv2.imshow('face record', frame)\n",
    "        if cv2.waitKey(1) == 27 or cnt == target_cnt:\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Collecting Samples Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LBP 얼굴 인식기 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os, glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting train data set:\n",
      "\t path:./faces/sk_0, 400files\n",
      "Strating LBP Model training...\n",
      "Model trained successfully\n"
     ]
    }
   ],
   "source": [
    "base_dir = './faces'\n",
    "train_data, train_labels = [], []\n",
    "dirs = [d for d in glob.glob(base_dir+\"/*\") if os.path.isdir(d)]\n",
    "print('Collecting train data set:')\n",
    "for dir in dirs:\n",
    "    id = dir.split('_')[1]\n",
    "    files = glob.glob(dir+'/*.jpg')\n",
    "    print('\\t path:%s, %dfiles'%(dir, len(files)))\n",
    "    for file in files:\n",
    "        img = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "        train_data.append(np.asarray(img, dtype = np.uint8))\n",
    "        train_labels.append(int(id))\n",
    "        \n",
    "train_data = np.asarray(train_data)\n",
    "train_labels = np.int32(train_labels)\n",
    "\n",
    "print('Strating LBP Model training...')\n",
    "model = cv2.face.LBPHFaceRecognizer_create()\n",
    "model.train(train_data, train_labels)\n",
    "model.write('./faces/all_face.xml')\n",
    "print(\"Model trained successfully\")\n",
    "                      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련된 LBP 얼굴 인식기로 얼굴 인식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os, glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = './faces'\n",
    "min_accuracy = 85\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('./data/haarcascade_frontalface_default.xml')\n",
    "model = cv2.face.LBPHFaceRecognizer_create()\n",
    "model.read(os.path.join(base_dir, 'all_face.xml'))\n",
    "\n",
    "dirs = [d for d in glob.glob(base_dir+'/*') if os.path.isdir(d)]\n",
    "names = dict([])\n",
    "for dir in dirs:\n",
    "    dir = os.path.basename(dir)\n",
    "    name, id = dir.split('_')\n",
    "    names[int(id)] = name\n",
    "    \n",
    "cap = cv2.VideoCapture(-1)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print('no frame')\n",
    "        break\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 255), 2)\n",
    "        face = frame[y:y+h, x:x+w]\n",
    "        face = cv2.resize(face, (200, 200))\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        label, confidence = model.predict(face)\n",
    "        if confidence < 400:\n",
    "            accuracy = int(100*(1-confidence/400))\n",
    "            if accuracy >= min_accuracy:\n",
    "                msg = '%s(%.0f%%)'%(names[label], accuracy)\n",
    "            else:\n",
    "                msg = 'Unknown'\n",
    "            \n",
    "        txt, base = cv2.getTextSize(msg, cv2.FONT_HERSHEY_PLAIN, 1, 3)\n",
    "        cv2.rectangle(frame, (x, y-base-txt[1]), (x+txt[0], y+txt[1]), (0, 255, 255), -1)\n",
    "        cv2.putText(frame, msg, (x, y), cv2.FONT_HERSHEY_PLAIN, 1, (200, 200, 200), 2, cv2.LINE_AA)\n",
    "    cv2.imshow('Face Recognition', frame)\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
